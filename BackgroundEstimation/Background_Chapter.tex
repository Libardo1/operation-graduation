% Activate the following line by filling in the right side. If for example the name of the root file is Main.tex, write
% "...root = Main.tex" if the chapter file is in the same directory, and "...root = ../Main.tex" if the chapter is in a subdirectory.
 
%!TEX root =  ../Thesis.tex

\chapter[Background Estimation]{Background Estimation}

Once the background has been reduced as much as practical using the trigger and kinematic cuts,
a reliable estimate of the shape and size of the remaining background is critical to optimizing
the exclusion limits.  In particular, since the reconstructed mass peak of the $b$-jets is so
broad in signal, a mis-estimation of the background shape can lead to systematic errors that
could wash out any possible signal (or worse, be mistaken for a signal where there is none).  

At the same time, the backgrounds in this analysis are challenging to estimate, either in Monte
Carlo or using data-driven methods.  Therefore, much of the work of this analysis is dedicated
to validating the background estimation and providing uncertainties for especially the shape 
of the background.  

\section{Background Estimation Strategy}
\label{sec:background_strategy}
As QCD is the dominant background in this analysis, it is important to understand
what flavors of QCD jets comprise the population of events that survive the cut
chain.  In order to do this, we apply the trigger and all cuts up to (but not including)
requiring a third $b$-tagged jet in the event; at this level of selection, we say
we are in the $bbx$ sample (because there are 2 $b$-tags already applied but the third
jet in the event can have any $b$-tag value.   

 The signal and background are then split into 3 exclusive regions, defined as follows:
\begin{itemize}
    \item bbb: one or more jets (in addition to the two triple-tagged jets) passing a tight (60\% working point)
 MV1 cut–-in effect, the full signal selection criteria
    \item bbloose: events failing the bbb classification but which have one or more jets passing a loose (80\%
 working point) MV1 cut
    \item bbanti: events that have no jets passing an 80\% MV1 cut-–effectively a veto on the presence of any
 b-tagged jets other than those firing the trigger
\end{itemize}


The bbanti and bbloose regions are depleted in signal and enriched in background, which allows
them to serve as control regions for the bbb signal region.  

Several background estimation strategies were attempted; we document all of those attempts 
in this section, including those that were not used in the final analysis.  The final strategy
uses the mass sidebands in the bbb signal region to estimate the background shape and
normalization in the signal region.  


\section{Background Estimation Method Based on Exponential Background Model and Sideband Fitting}
The background consists almost exclusively of QCD with 2 or more real $b$-jets, which 
fortunately has a $m_{bb}$ spectrum that does not have any peaks or other difficult
structure above about 350 GeV.  Below that mass, the trigger turn-on curve becomes
a major feature of the spectrum, making it difficult to fit.  Above that mass, there
is a smoothly falling distribution that we fit primarily with a decaying exponential.

In a few words, this fit strategy proceeds in the following way:
\begin{itemize}
    \item Start with a mass point
    \item Using the signal MC as a guide, select a window in $m_{bb}$ that encloses the
signal peak, along with as much of the mass sideband (on either side) as possible
    \item Fit the exponential within that window, in each of the 
tag regions (bbb, bbloose, bbanti) as well as keeping the 3, 4, and 5+ jet bins separate
    \item Use the fit result for the background long with signal templates taken from
 MC to extract the 
cross section that can be excluded at a 95\% confidence level
    \item Repeat for the next mass point
\end{itemize}

Although we have signal MC with $m_A$ values as low as 250 GeV, this fit strategy only
begins to work above 400 GeV, because of the trigger turn-on curve.  The fit window
used is \[340,900\] GeV for all signal mass points.

While the analysis was in development, it was blinded to avoid bias.  This was done 
by removing \textit{bbb} events from the data, and replacing them with a sample of
events with the same normalization drawn from the \textit{bbanti} distribution
in data.  For the final search, the \textit{bbb} events were swapped back in.


%\subsection{Mass Windows}
%A critical aspect of this strategy is selecting a mass window; large windows make for bigger
%sidebands which can help the fit result (more information for it to use in making a prediction)
%but also sometimes lead to convergence problems, since a larger window leaves more room
%for the background to fluctuate, or have shape subtleties that the polynomial has difficulty
%describing.  In fact, an early iteration of this fit strategy used the same large $m_{bb}$ 
%window \[320, 900 GeV\] but the background shape over that large region changes enough that
%the error matrix of the fit result was not positive-definite, leading to uncertainties that 
%could not be quantified reliably.   

%The final choices of mass windows are documented in Table~\ref{tab:mass_windows}.

%--------------------------------------------------------
%\begin{table}
%   \caption{The mass window used when fitting each signal mass point. \label{tab:mass_windows} }
%    \begin{tabular}{ c c c }
%    mass (GeV) & lower edge & upper edge \\
%    250        & 1.68682  & \\
%    280        & 1.92318 & \\
%    310        & 2.50849 & \\
%    350        & 3.23507 & \\
%    400        & 3.93561 & \\
%    450        & 4.71906 & \\
%    500        & 5.59454 & \\
%    550        & 6.84368 & \\
%    600        & 8.11044 & \\
%    650        & 9.26688 & \\
%    700        & 10.3760 & \\
%    800        & 12.5049 & \\
%    \end{tabular}
%\end{table}

%--------------------------------------------------------








%\section{Attempted (But Not Used) Background Estimation Methods}
% 
%A control-region-based binned background fit was attempted before the polynomial background fit was selected
%for the final version of the analysis.  This strategy is documented here, for the
%benefit of future analysts.  The strategy ultimately rests on having bb QCD MC for validation
%of a key assumption (that the shape of the $m_{bb}$ distribution is the same in QCD 
%regardless of the flavor of the third jet in the event).  The details of this sample
%are documented in Section~\ref{sec:bb_qcd_mc}, but unfortunately it was not produced in
%large statistics due to ATLAS-wide production problems.   
%
%For the alternative fit method documented here , we use the bbanti (and bbloose) control regions to predict the background shape in the bbb signal region.
%The background estimation strategy is to fit the $m_{bb}$ distribution in these three tag bins together. In
% practice, the bbanti bin dominates that fit because it has much higher statistics than the other two bins. In
% addition, we expect the bbanti bin to be heavily dominated by events that have exactly 2 b-jets, with the
% third jet being charm or light. Therefore, when we fit the three mbb distributions together, we are making
% an important assumption: the $m_{bb}$ distribution of the leading 2 jets is independent of the truth flavor of the third jet.
%
%This assumption is validated in several ways, which are detailed in this section.
%\begin{itemize}
%    \item Simple tag-based data-driven shape check
%    \item Matrix method data-driven shape check
%    \item bb QCD MC shape check
%\end{itemize}
% We also apply a jet-pT -based reweighting, to correct for any biases that might be introduced when
% b-tagging is applied to the third jet, which is also discussed in this section.
%
%
%\subsection{Shape Check after Applying $b$-Tagging}
%A simple first check of our background shape assumption is done on by plotting the mbb distribution
% in data for the bbb, bbloose and bbanti distributions tag bins; we would expect these to have different
% admixtures of bottom, charm and light jets in the third jet and so differences in these $m_{bb}$ distributions
% would hint at our assumption being violated. There are 12,308 bbb events, 9,049 bbloose, and 76,123
% bbanti events in 10\% of the 2012 data. The three mbb distributions are plotted in Figure~\ref{fig:mbb_data}, where the
% out-of-the-box distributions are shown on the left and the distributions are normalized to the same area
% on the right. No shape differences are apparent. Figure~\ref{fig:mbb_data} shows the distributions normalized to the
% same area and with a logarithmic y scale for easy shape comparison; no major shape differences appear
% there either.

%\begin{figure}[hbt]
%  \includegraphics[width=0.5\linewidth]{BackgroundEstimation/images/mbb_bbb_bbloose_bbanti_r200-215.pdf}
%  \includegraphics[width=0.5\linewidth]{BackgroundEstimation/images/mbb_bbb_bbloose_bbanti_r200-215_normalized.pdf}
%  \label{fig:mbb_data}
%  \caption{$m_{bb}$ distributions in data, based on the $b$-tag status of the third jet. 
%    \label{fig:mbb_data} }
%\end{figure}



\section{Background Shapes and Spurious Signal}
\cite{spurious_signal}












\subsection{Non-QCD Backgrounds}
\label{sec:non_qcd_bkgs}

\subsubsection{All-Hadronic $t\bar{t}$ Background}
When $t\bar{t}$ decays all-hadronically, it can create events with several high-$p_T$
jets and 2 or more $b$-tagged jets (where the $b$-tags come from both real $b$-quarks
and from mistagged light flavor).  We anticipate that, because it has a production
cross section that is much smaller than QCD, $t\bar{t}$ will not be a major background.
We confirm this assumption in MC by using the all-hadronic $t\bar{t}$ sample summarized
in Table~\ref{tab:ttbar_params}.


We find that in MC, all-hadronic $t\bar{t}$ has an efficiency of 7.5\% after
the EF\_2j35\_loose\_j145\_j35\_a4tchad trigger, and approximately 2\% efficiency
in the offline cuts relative to the trigger.  Estimating the $t\bar{t}$ cross section
as 165 pb, and a 44\% branching ratio in the all-hadronic decay channel, this gives
a 0.11 pb $t\bar{t}$ cross section expected after the trigger and offline cuts.  In the
full 2012 dataset, this amounts to about 2400 events.  While
this is not a negligible cross section compared to the signal, it is more than an
order of magnitude smaller than the QCD background.

In addition to checking the magnitude of the $t\bar{t}$ background, we check the shape
for any shape differences in the $m_{bb}$ distribution depending on the tag status of the
third jet, and do not find any major discrepancies that point toward $t\bar{t}$ as a
potential peaking background in the signal region. The $m_{bb}$ distributions in the
bbb, bbloose and bbanti bins for the all-hadronic $t\bar{t}$ can be found in Figure
~\ref{fig:ttbar_mbb}.




\begin{figure}[hbt]
\includegraphics[width=0.45\linewidth]{BackgroundEstimation/images/mbb_compare_bbb_bbloose_bbanti_ttbar.eps}
\includegraphics[width=0.45\linewidth]{BackgroundEstimation/images/mbb_compare_bbb_bbloose_bbanti_ttbar_logy.eps}
\caption{The $m_{bb}$ distributions for all-hadronic $t\bar{t}$ MC after the trigger and all offline cuts are applied (linear Y axis on the left, logarithmic scale on the right).  In addition to the overall cross-section, we also want to probe any shape differences that arise when the tag status changes on the third jet in the event.  No significant shape differences are seen.}
\label{fig:ttbar_mbb}
\end{figure}







%
%The background estimate is crucial to the analysis.  The QCD cross section at a hadron machine like the LHC is quite large; only a small subset of QCD events have 3 or more b-jets, but b-tagging does not have perfect performance and we expect a large contribution from QCD events in which one or more light or charm jets are b-tagged.
%
%The b-tagging in the trigger provides a handle for controlling the mistag background.  The L2, EF and offline MV1 b-tags are independent of each other, which is to say that (for example) the EF b-tagging decision on a given jet does not take into account whether the jet was tagged in L2, so we can improve the purity of our b-jet sample by requiring that the same jet pass L2, EF and MV1 tags.  




%The third jet in the event, however, will not be tagged by the trigger.  The jet will be tagged offline, but even after the offline tagging we expect there will be many events in which the third jet is not a b-jet, but is a mistagged light or charm jet.  The exact size of this background for light jets is given by equation \ref{eq:mistag}, and a similar equation can be written for charm jets.

%  \begin{equation}
%	N_{mistagged\ light\ jets} = N_{light\ jets} \times \epsilon_{light\ jet\ passing\ tag}
%\end{equation} \label{eq:mistag}

%The light mistag efficiency $\epsilon_{light\ jet\ passing\ tag}$ is computed and calibrated by the b-tagging performance group (see the b-tagging chapter for further details), so we need to compute the composition of light or charm jets in the original sample in order to estimate their contamination after b-tagging has been applied.  

%The QCD background is notoriously difficult to model in MC, and we find unacceptably low statistics in MC after our analysis cuts have been applied, so we use the data-driven matrix method to compute the QCD background composition as accurately as possible.  The matrix method makes use of the known efficiencies for tagging b, c and light jets, as well as information about how many jets pass a given b-tag, to arrive at 








%\section{Matrix Method Binning} \label{sec:matrix_method_binning}
%The tag counts $N_{tight}$, $N_{loose}$ and $N_{anti}$ obey Poisson statistics, and are prone to statistical fluctuations that can propagate through the method and make the flavor predictions less accurate.  As the number of events in a given bin goes up, the relative Poisson error goes down and the method generally gives better performance.  However, having bins that cover a large region in $p_T$/$\eta$ phase space comes with the complication that the b-tagging efficiencies might vary within that phase space, so assigning a single efficiency value in that bin would wash out the variation and create larger systematic errors.

%The matrix method binning thus must optimize the tradeoff between small statistical errors (large bins) and small efficiency-related systematic errors (small bins).  In order to probe the statistical error on the bin as a function of bin statistics, figure \ref{fig:bin_stats_errors} shows the performance (defined as (prediction-truth)/truth for a given flavor) of the matrix method versus the bin statistics.  The bin statistics is defined as the total number of events in a given bin, so it encompasses all tag categories.

%The results seen in Figure \ref{fig:bin_stats_errors} allow us to make several insights.  At low bin statistics, where Poisson errors are expected to have the most impact, the performance shows the most variation, indicating larger relative errors.  As the bin statistics increase, the performance converges asymptotically on 0, indicating that, for example, there is no great change in statistical errors between 400 events and 1000 events per bin.  With this in mind, and estimating that 300 events per bin is approximately where this asymptotic behavior becomes dominant, the bins should be drawn such that they each contain at least approximately 300 events.

% this figure is made by executing "binning_study" in matrix_method_systematics.py
%   the drawing is done in plotPerformanceVsStats in mms_plots.py
%   and generally lives in h4b/python/dovers.eps
%\includegraphics[width=\textwidth]{/Users/caitlinmalone/Documents/Thesis/BackgroundEstimation/images/dovers.eps}
%\label{fig:bin_stats_errors}

%\section{Closure Tests}
%Closure tests are applications of the matrix method in a very controlled situation, where the expected prediction of the method is easy to predict.  Closure tests allow bugs in the method to be more readily seen, so they can be targeted for further study.  In this implementation of the matrix method, closure tests are performed by deriving the efficiencies from a sample which is then used as the input to the matrix method.  

%\begin{enumerate}
%	\item In a Monte Carlo QCD sample, count the number of jets of a given flavor
%	\item In the same sample, count the number of jets of a given flavor passing a b-tag cut of a given working point 
%	\item Divide (2) by (1) to derive the b-tagging efficiency for that flavor and working point in QCD MC
%	\item Repeat for all flavors and working points
%	\item Run matrix method with the QCD MC events as the inputs and the derived efficiencies as the matrix inputs
%\end{enumerate}

%Mathematically, since the flavor counts can be expressed in terms of the efficiencies and the tag counts, the equations of the matrix method should give perfect predictions of the flavor counts in the QCD MC sample, modulo rounding or matrix inversion errors.  

%The closure test method outlined above can be repeated bin-by-bin for testing closure of each bin individually.  Then the difference between the prediction and MC truth in each bin for each flavor can be plotted; the difference should be very close to zero.

%\section{Statistical Errors}



%\section{Systematic Errors}
%b-tagging systematics in VH:  https://cds.cern.ch/record/1551231/files/ATL-COM-PHYS-2013-697.pdf
%Unlike statistical errors, the systematic errors of the matrix method do not decrease as the method is run over more jets.  In practice, the systematic errors of the method arise from deviations between the efficiencies that are used in the matrix and the true efficiencies of the input sample.  Such deviations can come from several places, most notably sample dependence and Monte Carlo vs. data differences. 

%The sample on which the efficiencies are derived can affect what values are computed for the efficiencies themselves.  The b-tagging efficiencies at ATLAS are computed on a $t\bar{t}$ sample, which generally does not have identical kinematics to a QCD sample.   





